# اسم سير العمل
name: Scrape Products Data

# متى يتم تشغيل هذا السير؟
on:
  # تشغيل يدوي من تبويب Actions في جيت هب
  workflow_dispatch:
  # تشغيل تلقائي كل يوم الساعة 02:00 بالتوقيت العالمي UTC
  schedule:
    - cron: '0 2 * * *'

# المهام التي سيتم تنفيذها
jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest

    # منح الأذونات الصريحة للروبوت
    permissions:
      contents: write

    steps:
      # الخطوة 1: نسخ محتويات المستودع
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # جلب السجل الكامل للمستودع (مهم للإجراء الجديد)
          fetch-depth: 0

      # الخطوة 2: تثبيت بايثون
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # الخطوة 3: تثبيت المكتبات المطلوبة
      - name: Install dependencies
        run: pip install -r requirements.txt

      # الخطوة 4: تشغيل كود بايثون لجلب البيانات
      - name: Run scraper script
        run: python scraper.py

      # الخطوة 5: استخدام إجراء متخصص للرفع (الحل الجديد)
      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Auto-update products data"
          # سيقوم فقط برفع الملف إذا تغير بالفعل
          file_pattern: 'products.json' 
